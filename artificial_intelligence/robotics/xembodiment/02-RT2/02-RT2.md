# RT2

## RT-2要点
- 跨模态的语言实现中，视觉token和文本token进行拼接后基于transforme计算和视觉和文本进行cross attention的计算两者的区别以及性能的影响？拼接的计算量和参数量都要大一些，性能上提升呢？
- rt2中的action预测的是增量delta，rt1中直接预测的是动作变量
- RT-2直接在VLM的基础上利用通用视觉语言的能力将行为的预测扩展为language token实现了VLM到VLA的扩展
- 支持web scale data和机器人data的co-finetune
- ViT模型结构形式化描述

$$
\begin{array}{rlrl}
\mathbf{x} & \in \mathbb{R}^{H \times W \times C} \longrightarrow \mathbf{x}_p \in \mathbb{R}^{N \times\left(P^2 \cdot C\right)} \quad N=H W / P^2 \\
\mathbf{z}_0 & =\left[\mathbf{x}_{\text {class }} ; \mathbf{x}_p^1 \mathbf{E} ; \mathbf{x}_p^2 \mathbf{E} ; \cdots ; \mathbf{x}_p^N \mathbf{E}\right]+\mathbf{E}_{\text {pos }}, & & \mathbf{E} \in \mathbb{R}^{\left(P^2 \cdot C\right) \times D}, \mathbf{E}_{\text {pos }} \in \mathbb{R}^{(N+1) \times D} \\
\mathbf{z}_{\ell}^{\prime} & =\operatorname{MSA}\left(\operatorname{LN}\left(\mathbf{z}_{\ell-1}\right)\right)+\mathbf{z}_{\ell-1}, & & \ell=1 \ldots L \\
\mathbf{z}_{\ell} & =\operatorname{MLP}\left(\operatorname{LN}\left(\mathbf{z}_{\ell}^{\prime}\right)\right)+\mathbf{z}_{\ell}^{\prime}, & & \ell=1 \ldots L \\
\mathbf{y} & =\operatorname{LN}\left(\mathbf{z}_L^0\right) & &
\end{array}
$$