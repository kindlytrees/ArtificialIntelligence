# RT1

- 视觉信息Univeral Sentence Encoder，RT-1中的Universal Sentence Encoder如何实现，基于bert的cls输出吗，还是其他的wordembedding的平均等实现
- FiLM的实现是和视觉信号进行一个类似于zero conv的融合操作，而不是基于cross attention机制来进行实现的
- RT1数据集简介


### rt-1中7个机械臂运动变量+3个底盘运动变量都可以量化为256个bins，然后还有一个模式切换变量，只有三种状态，是否分类的时候就分类为3类，也就是10输出，分别连接256个分类任务，1个输出接出3个分类任务，这和一般的token表示的含义还不太一样，因为每个输出的token随都是256类，但结果含义表示不同？不过可以统一以token来看对吗？

论文中说是decoder only结构，但图像输入的信息可以采用双向注意力机制，仅仅action token的序列需要因果注意力机制，这种混合的方式如何更好的理解？

辅助gemini回答：

您提的这个问题，精准地指出了近年来在大型序列模型（尤其是多模态模型）中一个非常重要且普遍的设计模式。您对“decoder-only”、“双向注意力”和“因果注意力”的理解非常到位，现在我们来把它们如何优雅地“混合”在一起讲清楚。

**核心思想：通过精心设计的注意力掩码（Attention Mask），在同一个Transformer Decoder模块内，实现对不同模态输入的不同注意力行为。**

让我们用一个形象的比喻来开始，然后再深入技术细节。

### 形象比喻：一场特殊的考试

想象一下你正在参加一场特殊的考试，试卷分为两部分：

1.  **第一部分：背景材料（图像+语言指令）**。这部分是“开卷”的。对于任何一个背景材料中的信息点（比如图像的一个区域），你可以**自由地、反复地查阅**所有其他的背景材料信息（其他图像区域、完整的语言指令），没有任何限制。这就像**双向注意力**，信息可以自由流动。

2.  **第二部分：问答题（生成动作序列）**。这部分是“闭卷”的。当你回答第3个问题时，你**只能看到**前面第1、2个问题的答案，以及所有的背景材料。你**绝对不能**看到后面第4、5...个问题的答案。这就像**因果注意力（causal attention）**，信息只能单向流动（从过去到未来）。

RT-1的Transformer Decoder就像是这样一个“考生”。它在处理同一个序列时，对序列的不同部分采用了不同的“考试规则”。

### 技术实现：注意力掩码的力量 (The Magic of the Attention Mask)

标准的Transformer Decoder是如何实现这种混合模式的呢？答案就在于**注意力掩码（Attention Mask）**。

在计算 `Attention_Scores = softmax((Q · K^T) / sqrt(d_k) + M)` 时，那个矩阵 `M` 就是注意力掩码。它是一个与 `Q · K^T` 同样大小的矩阵，通常由`0`和`-∞`（一个非常大的负数）组成。

*   如果 `M[i, j] = 0`，则位置 `i` 的token可以关注位置 `j` 的token。
*   如果 `M[i, j] = -∞`，则softmax之后，位置 `i` 对 `j` 的注意力权重会趋近于0，相当于“屏蔽”了这次关注。

现在，我们来看看RT-1中这个掩码矩阵是如何构建的。假设输入序列的结构是：
`[I1, I2, ..., I48, L, A1, A2, ..., A11]`
其中 `I` 是图像token，`L` 是语言token，`A` 是动作token。

这个序列总长度为 `48 + 1 + 11 = 60`。我们的注意力掩码就是一个 `60x60` 的矩阵。

**这个 `60x60` 的掩码矩阵可以被划分为四个区域：**



1.  **左上角区域（视觉/语言 -> 视觉/语言）**：
    *   **行为**：这部分对应着“背景材料”之间的相互审阅。一个图像token可以关注所有其他的图像token和语言token。一个语言token也可以关注所有的图像token。
    *   **掩码**：这个区域的掩码值**全部为0**。这实现了**双向注意力（Bi-directional Attention）**。
    *   **作用**：让模型充分理解视觉场景和语言指令之间的复杂关系，例如，将指令中的“蓝色杯子”与图像中蓝色杯子的像素区域对应起来。

2.  **右下角区域（动作 -> 动作）**：
    *   **行为**：这部分对应着“回答问题”。当生成第 `k` 个动作token时，它只能关注它自己和它前面的动作token（`A1` 到 `Ak`）。
    *   **掩码**：这是一个**下三角矩阵**。对角线及以下为 `0`，严格上三角部分为 `-∞`。这实现了**因果注意力（Causal Attention）**，也叫自回归注意力。
    *   **作用**：保证了动作生成的自回归特性，即预测当前动作时不能“偷看”未来的动作。

3.  **右上角区域（视觉/语言 -> 动作）**：
    *   **行为**：当生成任何一个动作token时，它可以关注**所有**的视觉和语言输入。
    *   **掩码**：这个区域的掩码值**全部为0**。
    *   **作用**：这是模型执行任务的依据。在生成动作的每一步，模型都会重新审视整个场景和指令，来决定下一步该怎么做。

4.  **左下角区域（动作 -> 视觉/语言）**：
    *   **行为**：理论上，视觉和语言token也可以关注已生成的动作token。
    *   **掩码**：这个区域的掩码值也**全部为0**。
    *   **作用**：这允许模型在处理输入时，考虑到已经开始执行的动作。例如，如果模型已经生成了“手臂向下移动”的动作，那么在下一帧图像的理解中，它可能会更关注手臂下方的物体。这使得整个过程更加动态和连贯。

### 总结：如何更好地理解这种混合方式？

1.  **统一的架构，差异化的行为**：要认识到这并不是两个不同的模型拼接而成，而是**同一个Transformer Decoder模块**，通过一个精心设计的注意力掩码，对输入序列的不同部分实现了不同的信息流模式。

2.  **职责分离**：可以将其理解为一种职责上的分离。
    *   序列的前半部分（图像+语言）扮演着**Encoder的角色**，负责深度理解和融合上下文信息（因此需要双向注意力）。
    *   序列的后半部分（动作）扮演着**Decoder的角色**，负责基于前面的理解，逐步生成输出（因此需要因果注意力）。

3.  **“Decoder-Only”的真正含义**：当论文中说这是一个“Decoder-Only”架构时，它的意思是整个模型的基础构建块是**Transformer Decoder Block**（即带有因果掩码能力的自注意力块），而不是指整个序列都必须严格遵守因果关系。通过调整注意力掩码，一个Decoder Block可以完美地模拟出Encoder的行为（全0掩码）或传统的Decoder行为（因果掩码），或者像RT-1这样，实现两者的混合。

这种设计非常强大和灵活，它已经成为当前多模态大模型（如Flamingo、Gato等）的标准范式，因为它用一种统一而优雅的方式解决了不同模态信息流需求的根本矛盾。

## 参考资料
- https://research.google/blog/rt-1-robotics-transformer-for-real-world-control-at-scale/
- https://github.com/google-research/robotics_transformer
- pytorch版本复现： https://github.com/lucidrains/robotic-transformer-pytorch 