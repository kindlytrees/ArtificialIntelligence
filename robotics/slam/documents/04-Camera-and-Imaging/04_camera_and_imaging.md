# Camera and Imaging

rgb-d图像中rgb和一般的图像是一致的吗，然后每一个像素多一个深度信息？还是基于点云的更稀疏的表示？

RGB-D图像 = 一个标准的RGB图像 + 一个与之对齐的深度图像（Depth Map）

这也是一个二维的像素网格，并且其分辨率与RGB图像完全相同。
关键区别在于，这个图像的每个像素值不是颜色，而是一个数值，代表该像素对应场景中的点到相机传感器的距离（深度）。
这个深度值通常用16位整数（如0-65535）或32位浮点数表示，单位通常是毫米（mm）或米（m）。
例如，在深度图中，像素(100, 200)的值可能是1500，意味着在彩色图中(100, 200)位置的物体，其真实世界中的点距离相机1500毫米（1.5米）。
深度图中可能会有无效值（比如为0或者一个最大值），表示这个像素点无法测得有效深度（如被遮挡、距离太远、反光材质等）。


从RGB-D图像到点云的转换（这个过程也叫“反投影” Unprojection）：
我们可以利用相机内参（Camera Intrinsics），将RGB-D图像的每个像素转换成一个3D空间中的点。
对于RGB-D图像中的任意一个像素 (u, v)：
从RGB图像的 (u, v) 位置获取其颜色 (R, G, B)。
从深度图像的 (u, v) 位置获取其深度值 D。
利用相机内参（焦距 fx, fy 和主点 cx, cy）和以下公式，计算出该点在相机坐标系下的3D坐标 (X, Y, Z)：
Z = D
X = (u - cx) * Z / fx
Y = (v - cy) * Z / fy
对图像中的每一个有效像素都执行这个操作，我们就得到了一个带有着色的三维点云。因为RGB-D图像本身是稠密的，所以这样生成的点云也是稠密的。

内参包括两个部分，相机成像相关参数，以及畸变相关参数
